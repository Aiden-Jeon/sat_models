{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"mix_data_advanced_model.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEiWqpvJzG22","executionInfo":{"status":"ok","timestamp":1606446295554,"user_tz":480,"elapsed":5676,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"ff81b234-57ac-4f81-902b-598b2ff4a9af"},"source":["import dill\n","from copy import deepcopy\n","import time\n","import random\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","\n","import nltk\n","\n","nltk.download(\"punkt\")\n","from nltk.tokenize import word_tokenize\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchtext.data import Field\n","from torchtext.data import TabularDataset\n","from torchtext.data import BucketIterator\n","from torchtext.data import Iterator"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DXvvT31XzRa4","executionInfo":{"status":"ok","timestamp":1606446295555,"user_tz":480,"elapsed":5673,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["RANDOM_SEED = 2020\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","\n","# DATA_PATH = \"data/processed/\"\n","DATA_PATH = \"/content/\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYHxi853tUYt"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"9ld1UO09bsc_","executionInfo":{"status":"ok","timestamp":1606446295556,"user_tz":480,"elapsed":5671,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["import pandas as pd\n","\n","\n","train_df = []\n","valid_df = []\n","test_df = []\n","for data_name in [\"sat\", \"cola\"]:\n","    train_df += [pd.read_csv(f\"{DATA_PATH}/{data_name}_train.tsv\", sep=\"\\t\")]\n","    valid_df += [pd.read_csv(f\"{DATA_PATH}/{data_name}_valid.tsv\", sep=\"\\t\")]\n","\n","train_df = pd.concat(train_df)\n","valid_df = pd.concat(valid_df)\n","\n","train_df.to_csv(\"mix_train.tsv\", sep=\"\\t\", index=False)\n","valid_df.to_csv(\"mix_valid.tsv\", sep=\"\\t\", index=False)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8Twwhw9zPdJ","executionInfo":{"status":"ok","timestamp":1606446296566,"user_tz":480,"elapsed":6679,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["TEXT = Field(\n","    sequential=True,\n","    use_vocab=True,\n","    tokenize=word_tokenize,\n","    lower=True,\n","    batch_first=True,\n",")\n","LABEL = Field(\n","    sequential=False,\n","    use_vocab=False,\n","    batch_first=True,\n",")\n","\n","\n","mix_train_data, mix_valid_data = TabularDataset.splits(\n","    path=DATA_PATH,\n","    train=\"mix_train.tsv\",\n","    validation=\"mix_valid.tsv\",\n","    format=\"tsv\",\n","    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n","    skip_header=1,\n",")\n","\n","TEXT.build_vocab(mix_train_data, min_freq=2)\n","\n","\n","mix_train_iterator, mix_valid_iterator = BucketIterator.splits(\n","    (mix_train_data, mix_valid_data),\n","    batch_size=32,\n","    device=None,\n","    sort=False,\n",")\n","\n","sat_test_data = TabularDataset(\n","    path=f\"{DATA_PATH}/sat_test.tsv\",\n","    format=\"tsv\",\n","    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n","    skip_header=1\n",")\n","\n","sat_test_iterator = BucketIterator(\n","    sat_test_data,\n","    batch_size=8, \n","    device=None,\n","    sort=False,\n","    shuffle=False\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSA7RDIdtUYt"},"source":["## LSTM Pooling Classifier"]},{"cell_type":"code","metadata":{"id":"VR3ZHB5AtiIY","executionInfo":{"status":"ok","timestamp":1606446296568,"user_tz":480,"elapsed":6679,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["class LSTMPoolingClassifier(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n","        super(LSTMPoolingClassifier, self).__init__()\n","        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n","        self.hidden_size = hidden_size\n","        self.embedding_dim = embedding_dim\n","        self.num_layers = num_layers\n","        self.ih2h = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n","                            bidirectional=True, batch_first=True, dropout=0.5)\n","        self.pool2o = nn.Linear(2 * hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        self.softmax = nn.Softmax()\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):\n","        x = self.embed_layer(x)\n","        o, _ = self.ih2h(x)\n","        pool = nn.functional.max_pool1d(o.transpose(1, 2), x.shape[1])\n","        pool = pool.transpose(1, 2).squeeze()\n","        pool = self.dropout(pool)\n","        output = self.sigmoid(self.pool2o(pool))\n","        return output.squeeze()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHX9pXijzdKM","executionInfo":{"status":"ok","timestamp":1606446296568,"user_tz":480,"elapsed":6677,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["def train(model: nn.Module,\n","          iterator: Iterator,\n","          optimizer: torch.optim.Optimizer,\n","          criterion: nn.Module,\n","          device: str):\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for _, batch in enumerate(iterator):\n","        optimizer.zero_grad()\n","\n","        text = batch.text\n","        if text.shape[0] > 1:\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def evaluate(model: nn.Module,\n","             iterator: Iterator,\n","             criterion: nn.Module,\n","             device: str):\n","    model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","        for _, batch in enumerate(iterator):\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def test(\n","    model: nn.Module,\n","    iterator: Iterator,\n","    device: str):\n","\n","    with torch.no_grad():\n","        y_real = []\n","        y_pred = []\n","        model.eval()\n","        for batch in iterator:\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","\n","            output = model(text).flatten().cpu()\n","\n","            y_real += [label]\n","            y_pred += [output]\n","\n","        y_real = torch.cat(y_real)\n","        y_pred = torch.cat(y_pred)\n","\n","    fpr, tpr, _ = roc_curve(y_real, y_pred)\n","    auroc = auc(fpr, tpr)\n","\n","    return auroc\n","\n","def epoch_time(start_time: int,\n","               end_time: int):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H1bLV6MdtUYt"},"source":["## Pretrain with cola dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4h9dm2HxC-rR","executionInfo":{"status":"ok","timestamp":1606446402831,"user_tz":480,"elapsed":112907,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"472165ae-2872-4bd0-aa72-047b8d8b8437"},"source":["PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","N_EPOCHS = 20\n","\n","lstm_classifier = LSTMPoolingClassifier(\n","    num_embeddings=len(TEXT.vocab),\n","    embedding_dim=100,\n","    hidden_size=200,\n","    num_layers=4,\n","    pad_idx=PAD_IDX,\n",")\n","if torch.cuda.is_available():\n","    device = \"cuda:0\"\n","else:\n","    device = \"cpu\"\n","_ = lstm_classifier.to(device)\n","\n","optimizer = torch.optim.Adam(lstm_classifier.parameters())\n","bce_loss_fn = nn.BCELoss()\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(lstm_classifier, mix_train_iterator, optimizer, bce_loss_fn, device)\n","    valid_loss = evaluate(lstm_classifier, mix_valid_iterator, bce_loss_fn, device)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n","    print(f\"\\t Val. Loss: {valid_loss:.5f}\")\n","\n","test_auroc = test(lstm_classifier, sat_test_iterator, device)\n","\n","print(f\"| SAT Dataset Test AUROC: {test_auroc:.5f}\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 5s\n","\tTrain Loss: 0.60662\n","\t Val. Loss: 0.65990\n","Epoch: 02 | Time: 0m 4s\n","\tTrain Loss: 0.59503\n","\t Val. Loss: 0.65051\n","Epoch: 03 | Time: 0m 4s\n","\tTrain Loss: 0.56600\n","\t Val. Loss: 0.68920\n","Epoch: 04 | Time: 0m 4s\n","\tTrain Loss: 0.52828\n","\t Val. Loss: 0.69242\n","Epoch: 05 | Time: 0m 4s\n","\tTrain Loss: 0.47584\n","\t Val. Loss: 0.76790\n","Epoch: 06 | Time: 0m 4s\n","\tTrain Loss: 0.41448\n","\t Val. Loss: 0.84083\n","Epoch: 07 | Time: 0m 4s\n","\tTrain Loss: 0.35734\n","\t Val. Loss: 0.92759\n","Epoch: 08 | Time: 0m 4s\n","\tTrain Loss: 0.29494\n","\t Val. Loss: 1.15169\n","Epoch: 09 | Time: 0m 4s\n","\tTrain Loss: 0.24994\n","\t Val. Loss: 1.18178\n","Epoch: 10 | Time: 0m 4s\n","\tTrain Loss: 0.20554\n","\t Val. Loss: 1.26133\n","Epoch: 11 | Time: 0m 4s\n","\tTrain Loss: 0.16845\n","\t Val. Loss: 1.53324\n","Epoch: 12 | Time: 0m 4s\n","\tTrain Loss: 0.14884\n","\t Val. Loss: 1.58437\n","Epoch: 13 | Time: 0m 4s\n","\tTrain Loss: 0.11677\n","\t Val. Loss: 1.63313\n","Epoch: 14 | Time: 0m 4s\n","\tTrain Loss: 0.11594\n","\t Val. Loss: 1.62229\n","Epoch: 15 | Time: 0m 4s\n","\tTrain Loss: 0.09337\n","\t Val. Loss: 1.72785\n","Epoch: 16 | Time: 0m 4s\n","\tTrain Loss: 0.07466\n","\t Val. Loss: 1.88143\n","Epoch: 17 | Time: 0m 4s\n","\tTrain Loss: 0.07115\n","\t Val. Loss: 1.89253\n","Epoch: 18 | Time: 0m 4s\n","\tTrain Loss: 0.06141\n","\t Val. Loss: 1.89261\n","Epoch: 19 | Time: 0m 4s\n","\tTrain Loss: 0.05871\n","\t Val. Loss: 1.98365\n","Epoch: 20 | Time: 0m 4s\n","\tTrain Loss: 0.05234\n","\t Val. Loss: 2.05295\n","| SAT Dataset Test AUROC: 0.34615\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VWzd0F_rtrhP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606446402979,"user_tz":480,"elapsed":113048,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"af18cfb2-eb7c-455c-ad30-b4bde17ab26d"},"source":["_ = lstm_classifier.cpu()\n","mix_lstm_sat_test_auroc = test(lstm_classifier, sat_test_iterator, \"cpu\")\n","\n","print(f\"| SAT Dataset Test AUROC: {mix_lstm_sat_test_auroc:.5f}\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["| SAT Dataset Test AUROC: 0.34615\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oUf4ZlkJXnTH","executionInfo":{"status":"ok","timestamp":1606446403139,"user_tz":480,"elapsed":113206,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["with open(\"mix_data_advanced_model.dill\", \"wb\") as f:\n","    model = {\n","        \"TEXT\": TEXT,\n","        \"LABEL\": LABEL,\n","        \"classifier\": lstm_classifier\n","    }\n","    dill.dump(model, f)"],"execution_count":9,"outputs":[]}]}