{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238,
     "status": "ok",
     "timestamp": 1604872383806,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "WEiWqpvJzG22",
    "outputId": "3a6ffc01-daa2-486e-c381-b2eed937c43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import BucketIterator\n",
    "from torchtext.data import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1604872383987,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "DXvvT31XzRa4"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2020\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DATA_PATH = \"data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1604872385048,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "k8Twwhw9zPdJ"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True,\n",
    "    use_vocab=True,\n",
    "    tokenize=word_tokenize,\n",
    "    lower=True,\n",
    "    batch_first=True,\n",
    ")\n",
    "LABEL = Field(\n",
    "    sequential=False,\n",
    "    use_vocab=False,\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "\n",
    "cola_train_data, cola_valid_data, cola_test_data = TabularDataset.splits(\n",
    "    path=DATA_PATH,\n",
    "    train=\"cola_train.tsv\",\n",
    "    validation=\"cola_valid.tsv\",\n",
    "    test=\"cola_test.tsv\",\n",
    "    format=\"tsv\",\n",
    "    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
    "    skip_header=1\n",
    ")\n",
    "\n",
    "TEXT.build_vocab(cola_train_data, min_freq=2)\n",
    "\n",
    "\n",
    "cola_train_iterator, cola_valid_iterator, cola_test_iterator = BucketIterator.splits(\n",
    "    (cola_train_data, cola_valid_data, cola_test_data), \n",
    "    batch_size=32, \n",
    "    device=None,\n",
    "    sort=False,\n",
    ")\n",
    "\n",
    "\n",
    "sat_train_data, sat_valid_data, sat_test_data = TabularDataset.splits(\n",
    "    path=DATA_PATH,\n",
    "    train=\"sat_train.tsv\",\n",
    "    validation=\"sat_valid.tsv\",\n",
    "    test=\"sat_test.tsv\",\n",
    "    format=\"tsv\",\n",
    "    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n",
    "    skip_header=1\n",
    ")\n",
    "\n",
    "sat_train_iterator, sat_valid_iterator, sat_test_iterator = BucketIterator.splits(\n",
    "    (sat_train_data, sat_valid_data, sat_test_data), \n",
    "    batch_size=8, \n",
    "    device=None,\n",
    "    sort=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2461,
     "status": "ok",
     "timestamp": 1604872385049,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "-ycMzmLHzbI9"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, bidirectional=True, dropout=0.5\n",
    "        )\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size*2, hidden_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        embed_x = self.embed_layer(x)\n",
    "        output, (_, _) = self.lstm_layer(embed_x)\n",
    "        last_output = output[:,-1,:]\n",
    "        last_output = self.last_layer(last_output)\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2452,
     "status": "ok",
     "timestamp": 1604872385049,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "xHX9pXijzdKM"
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "          iterator: Iterator,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          device: str):\n",
    "    # https://tutorials.pytorch.kr/beginner/torchtext_translation_tutorial.html\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for _, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text = batch.text\n",
    "        if text.shape[0] > 1:\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: Iterator,\n",
    "             criterion: nn.Module,\n",
    "             device: str):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(iterator):\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(text).flatten()\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    iterator: Iterator,\n",
    "    device: str):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_real = []\n",
    "        y_pred = []\n",
    "        model.eval()\n",
    "        for batch in iterator:\n",
    "            text = batch.text\n",
    "            label = batch.label.type(torch.FloatTensor)\n",
    "            text = text.to(device)\n",
    "\n",
    "            output = model(text).flatten().cpu()\n",
    "\n",
    "            y_real += [label]\n",
    "            y_pred += [output]\n",
    "\n",
    "        y_real = torch.cat(y_real)\n",
    "        y_pred = torch.cat(y_pred)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    return auroc\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain with cola dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126051,
     "status": "ok",
     "timestamp": 1604872508655,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "so3L6wyQzeEI",
    "outputId": "51e98f45-4cfd-4606-f83f-b7e6419f74df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 5s\n",
      "\tTrain Loss: 0.61555\n",
      "\t Val. Loss: 0.61686\n",
      "Epoch: 02 | Time: 0m 5s\n",
      "\tTrain Loss: 0.61094\n",
      "\t Val. Loss: 0.61838\n",
      "Epoch: 03 | Time: 0m 5s\n",
      "\tTrain Loss: 0.61013\n",
      "\t Val. Loss: 0.61736\n",
      "Epoch: 04 | Time: 0m 5s\n",
      "\tTrain Loss: 0.63810\n",
      "\t Val. Loss: 0.61793\n",
      "Epoch: 05 | Time: 0m 5s\n",
      "\tTrain Loss: 0.61023\n",
      "\t Val. Loss: 0.61750\n",
      "Epoch: 06 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60996\n",
      "\t Val. Loss: 0.61784\n",
      "Epoch: 07 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60867\n",
      "\t Val. Loss: 0.61822\n",
      "Epoch: 08 | Time: 0m 5s\n",
      "\tTrain Loss: 0.61013\n",
      "\t Val. Loss: 0.61761\n",
      "Epoch: 09 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60868\n",
      "\t Val. Loss: 0.61935\n",
      "Epoch: 10 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60879\n",
      "\t Val. Loss: 0.61786\n",
      "Epoch: 11 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60929\n",
      "\t Val. Loss: 0.61792\n",
      "Epoch: 12 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60853\n",
      "\t Val. Loss: 0.62832\n",
      "Epoch: 13 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60849\n",
      "\t Val. Loss: 0.61932\n",
      "Epoch: 14 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60850\n",
      "\t Val. Loss: 0.61786\n",
      "Epoch: 15 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60764\n",
      "\t Val. Loss: 0.61783\n",
      "Epoch: 16 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60847\n",
      "\t Val. Loss: 0.61964\n",
      "Epoch: 17 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60861\n",
      "\t Val. Loss: 0.61838\n",
      "Epoch: 18 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60832\n",
      "\t Val. Loss: 0.61842\n",
      "Epoch: 19 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60861\n",
      "\t Val. Loss: 0.61931\n",
      "Epoch: 20 | Time: 0m 5s\n",
      "\tTrain Loss: 0.60812\n",
      "\t Val. Loss: 0.61743\n",
      "| Test AUROC: 0.42215\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_classifier = LSTMClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "_ = lstm_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(lstm_classifier, cola_train_iterator, optimizer, bce_loss_fn, device)\n",
    "    valid_loss = evaluate(lstm_classifier, cola_valid_iterator, bce_loss_fn, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f}')\n",
    "\n",
    "test_auroc = test(lstm_classifier, cola_test_iterator, device)\n",
    "\n",
    "print(f'| Test AUROC: {test_auroc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126044,
     "status": "ok",
     "timestamp": 1604872508656,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "Y_-a20XpdJZx",
    "outputId": "2546cd52-c2c9-4839-fde7-ab8dd292b3f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38383838383838387"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_sat_test_auroc = test(lstm_classifier, sat_test_iterator, device)\n",
    "lstm_sat_test_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131595,
     "status": "ok",
     "timestamp": 1604872514216,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "WG9ulCznWHZ8",
    "outputId": "f92bf296-f3f9-44da-f603-fac77c58c4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 0.47950\n",
      "\t Val. Loss: 0.49541\n",
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46661\n",
      "\t Val. Loss: 0.49877\n",
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46235\n",
      "\t Val. Loss: 0.49688\n",
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46105\n",
      "\t Val. Loss: 0.49632\n",
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 0.48165\n",
      "\t Val. Loss: 0.50624\n",
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46324\n",
      "\t Val. Loss: 0.51241\n",
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46848\n",
      "\t Val. Loss: 0.50255\n",
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46075\n",
      "\t Val. Loss: 0.50101\n",
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 0.47238\n",
      "\t Val. Loss: 0.49961\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46845\n",
      "\t Val. Loss: 0.50225\n",
      "Epoch: 11 | Time: 0m 0s\n",
      "\tTrain Loss: 0.45874\n",
      "\t Val. Loss: 0.50258\n",
      "Epoch: 12 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46244\n",
      "\t Val. Loss: 0.50454\n",
      "Epoch: 13 | Time: 0m 0s\n",
      "\tTrain Loss: 0.45688\n",
      "\t Val. Loss: 0.50131\n",
      "Epoch: 14 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46865\n",
      "\t Val. Loss: 0.50134\n",
      "Epoch: 15 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46426\n",
      "\t Val. Loss: 0.49735\n",
      "Epoch: 16 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46052\n",
      "\t Val. Loss: 0.49818\n",
      "Epoch: 17 | Time: 0m 0s\n",
      "\tTrain Loss: 0.44465\n",
      "\t Val. Loss: 0.49533\n",
      "Epoch: 18 | Time: 0m 0s\n",
      "\tTrain Loss: 0.47137\n",
      "\t Val. Loss: 0.49773\n",
      "Epoch: 19 | Time: 0m 0s\n",
      "\tTrain Loss: 0.47226\n",
      "\t Val. Loss: 0.49515\n",
      "Epoch: 20 | Time: 0m 0s\n",
      "\tTrain Loss: 0.47454\n",
      "\t Val. Loss: 0.49255\n",
      "| Test AUROC: 0.43939\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(lstm_classifier, sat_train_iterator, optimizer, bce_loss_fn, device)\n",
    "    valid_loss = evaluate(lstm_classifier, sat_valid_iterator, bce_loss_fn, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f}')\n",
    "\n",
    "lstm_tuned_test_auroc = test(lstm_classifier, sat_test_iterator, device)\n",
    "\n",
    "print(f'| Test AUROC: {lstm_tuned_test_auroc:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Pooling Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 131588,
     "status": "ok",
     "timestamp": 1604872514217,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "QrcozzWKs3zW"
   },
   "outputs": [],
   "source": [
    "class LSTMPoolingClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n",
    "        super(LSTMPoolingClassifier, self).__init__()\n",
    "        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.ih2h = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
    "                            bidirectional=True, batch_first=True, dropout=0.5)\n",
    "        self.pool2o = nn.Linear(2 * hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_layer(x)\n",
    "        o, _ = self.ih2h(x)\n",
    "        pool = nn.functional.max_pool1d(o.transpose(1, 2), x.shape[1])\n",
    "        pool = pool.transpose(1, 2).squeeze()\n",
    "        pool = self.dropout(pool)\n",
    "        output = self.sigmoid(self.pool2o(pool))\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain with cola dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219646,
     "status": "ok",
     "timestamp": 1604872602282,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "4h9dm2HxC-rR",
    "outputId": "350a925e-e0e4-4195-971f-ef5f35eacdf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 4s\n",
      "\tTrain Loss: 0.60776\n",
      "\t Val. Loss: 0.61853\n",
      "Epoch: 02 | Time: 0m 4s\n",
      "\tTrain Loss: 0.59857\n",
      "\t Val. Loss: 0.61682\n",
      "Epoch: 03 | Time: 0m 4s\n",
      "\tTrain Loss: 0.57342\n",
      "\t Val. Loss: 0.60749\n",
      "Epoch: 04 | Time: 0m 4s\n",
      "\tTrain Loss: 0.53378\n",
      "\t Val. Loss: 0.62361\n",
      "Epoch: 05 | Time: 0m 4s\n",
      "\tTrain Loss: 0.47542\n",
      "\t Val. Loss: 0.67913\n",
      "Epoch: 06 | Time: 0m 4s\n",
      "\tTrain Loss: 0.40751\n",
      "\t Val. Loss: 0.75237\n",
      "Epoch: 07 | Time: 0m 4s\n",
      "\tTrain Loss: 0.34357\n",
      "\t Val. Loss: 0.85223\n",
      "Epoch: 08 | Time: 0m 4s\n",
      "\tTrain Loss: 0.27945\n",
      "\t Val. Loss: 0.93242\n",
      "Epoch: 09 | Time: 0m 4s\n",
      "\tTrain Loss: 0.22622\n",
      "\t Val. Loss: 1.07371\n",
      "Epoch: 10 | Time: 0m 4s\n",
      "\tTrain Loss: 0.18782\n",
      "\t Val. Loss: 1.20898\n",
      "Epoch: 11 | Time: 0m 4s\n",
      "\tTrain Loss: 0.14294\n",
      "\t Val. Loss: 1.29697\n",
      "Epoch: 12 | Time: 0m 4s\n",
      "\tTrain Loss: 0.12605\n",
      "\t Val. Loss: 1.37011\n",
      "Epoch: 13 | Time: 0m 4s\n",
      "\tTrain Loss: 0.11195\n",
      "\t Val. Loss: 1.43069\n",
      "Epoch: 14 | Time: 0m 4s\n",
      "\tTrain Loss: 0.09254\n",
      "\t Val. Loss: 1.57049\n",
      "Epoch: 15 | Time: 0m 4s\n",
      "\tTrain Loss: 0.08187\n",
      "\t Val. Loss: 1.59783\n",
      "Epoch: 16 | Time: 0m 4s\n",
      "\tTrain Loss: 0.07441\n",
      "\t Val. Loss: 1.70109\n",
      "Epoch: 17 | Time: 0m 4s\n",
      "\tTrain Loss: 0.06148\n",
      "\t Val. Loss: 1.84308\n",
      "Epoch: 18 | Time: 0m 4s\n",
      "\tTrain Loss: 0.05330\n",
      "\t Val. Loss: 1.93802\n",
      "Epoch: 19 | Time: 0m 4s\n",
      "\tTrain Loss: 0.05466\n",
      "\t Val. Loss: 1.81034\n",
      "Epoch: 20 | Time: 0m 4s\n",
      "\tTrain Loss: 0.05920\n",
      "\t Val. Loss: 1.78350\n",
      "| Test AUROC: 0.54086\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "lstm_pool_classifier = LSTMPoolingClassifier(\n",
    "    num_embeddings=len(TEXT.vocab),\n",
    "    embedding_dim=100,\n",
    "    hidden_size=200,\n",
    "    num_layers=4,\n",
    "    pad_idx=PAD_IDX,\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "_ = lstm_pool_classifier.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_pool_classifier.parameters())\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(lstm_pool_classifier, cola_train_iterator, optimizer, bce_loss_fn, device)\n",
    "    valid_loss = evaluate(lstm_pool_classifier, cola_valid_iterator, bce_loss_fn, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f}')\n",
    "\n",
    "test_auroc = test(lstm_pool_classifier, cola_test_iterator, device)\n",
    "\n",
    "print(f'| Test AUROC: {test_auroc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219641,
     "status": "ok",
     "timestamp": 1604872602283,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "uuP-hCtadCDG",
    "outputId": "91b1fbb8-472a-4a93-b5d0-1b6190f8118e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6262626262626263"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_sat_test_auroc = test(lstm_pool_classifier, sat_test_iterator, device)\n",
    "pool_sat_test_auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230931,
     "status": "ok",
     "timestamp": 1604872613580,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "R2L-OLADWRbO",
    "outputId": "de74e361-cc4d-44f5-b434-8ab47350f202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 0.83396\n",
      "\t Val. Loss: 0.60393\n",
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 0.49799\n",
      "\t Val. Loss: 0.53601\n",
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 0.49876\n",
      "\t Val. Loss: 0.49614\n",
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 0.48081\n",
      "\t Val. Loss: 0.48205\n",
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 0.46224\n",
      "\t Val. Loss: 0.49455\n",
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 0.42684\n",
      "\t Val. Loss: 0.45782\n",
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 0.45990\n",
      "\t Val. Loss: 0.52117\n",
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 0.41528\n",
      "\t Val. Loss: 0.45893\n",
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 0.39553\n",
      "\t Val. Loss: 0.46371\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 0.34969\n",
      "\t Val. Loss: 0.47822\n",
      "Epoch: 11 | Time: 0m 0s\n",
      "\tTrain Loss: 0.31372\n",
      "\t Val. Loss: 0.55054\n",
      "Epoch: 12 | Time: 0m 0s\n",
      "\tTrain Loss: 0.26339\n",
      "\t Val. Loss: 0.55815\n",
      "Epoch: 13 | Time: 0m 0s\n",
      "\tTrain Loss: 0.26382\n",
      "\t Val. Loss: 0.66740\n",
      "Epoch: 14 | Time: 0m 0s\n",
      "\tTrain Loss: 0.27018\n",
      "\t Val. Loss: 0.55313\n",
      "Epoch: 15 | Time: 0m 0s\n",
      "\tTrain Loss: 0.31335\n",
      "\t Val. Loss: 0.56001\n",
      "Epoch: 16 | Time: 0m 0s\n",
      "\tTrain Loss: 0.23072\n",
      "\t Val. Loss: 0.56625\n",
      "Epoch: 17 | Time: 0m 0s\n",
      "\tTrain Loss: 0.20616\n",
      "\t Val. Loss: 0.61997\n",
      "Epoch: 18 | Time: 0m 0s\n",
      "\tTrain Loss: 0.19045\n",
      "\t Val. Loss: 0.61412\n",
      "Epoch: 19 | Time: 0m 0s\n",
      "\tTrain Loss: 0.24236\n",
      "\t Val. Loss: 0.58684\n",
      "Epoch: 20 | Time: 0m 0s\n",
      "\tTrain Loss: 0.24943\n",
      "\t Val. Loss: 0.65357\n",
      "| Test AUROC: 0.77778\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "N_EPOCHS = 20\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(lstm_pool_classifier, sat_train_iterator, optimizer, bce_loss_fn, device)\n",
    "    valid_loss = evaluate(lstm_pool_classifier, sat_valid_iterator, bce_loss_fn, device)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.5f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.5f}')\n",
    "\n",
    "pool_tuned_test_auroc = test(lstm_pool_classifier, sat_test_iterator, device)\n",
    "\n",
    "print(f'| Test AUROC: {pool_tuned_test_auroc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230926,
     "status": "ok",
     "timestamp": 1604872613581,
     "user": {
      "displayName": "J JS",
      "photoUrl": "",
      "userId": "03523663544813654809"
     },
     "user_tz": 480
    },
    "id": "iikFkuUaZqxf",
    "outputId": "2a54a2f9-3b5a-4b62-8e6d-fb71a2a11ecf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38383838383838387,\n",
       " 0.4393939393939394,\n",
       " 0.6262626262626263,\n",
       " 0.7777777777777778)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_sat_test_auroc, lstm_tuned_test_auroc, pool_sat_test_auroc, pool_tuned_test_auroc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMRktbttRsH+k0xmmbEFDe2",
   "collapsed_sections": [],
   "name": "cola_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
