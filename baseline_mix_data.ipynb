{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Baseline_mix_data.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WEiWqpvJzG22","executionInfo":{"status":"ok","timestamp":1606111349410,"user_tz":480,"elapsed":5666,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"004d6512-06a5-46ad-f2c0-6ffcc03f4939"},"source":["from copy import deepcopy\n","import time\n","import random\n","import numpy as np\n","from sklearn.metrics import roc_curve, auc\n","\n","import nltk\n","\n","nltk.download(\"punkt\")\n","from nltk.tokenize import word_tokenize\n","\n","import torch\n","import torch.nn as nn\n","\n","from torchtext.data import Field\n","from torchtext.data import TabularDataset\n","from torchtext.data import BucketIterator\n","from torchtext.data import Iterator"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DXvvT31XzRa4","executionInfo":{"status":"ok","timestamp":1606111349411,"user_tz":480,"elapsed":1894,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["RANDOM_SEED = 2020\n","torch.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","\n","# DATA_PATH = \"data/processed/\"\n","DATA_PATH = \"/content/\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fTocBve5qHZX","executionInfo":{"status":"ok","timestamp":1606111357758,"user_tz":480,"elapsed":646,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["import pandas as pd\n","\n","train_df = []\n","valid_df = []\n","test_df = []\n","for data_name in [\"sat\", \"cola\"]:\n","    train_df += [pd.read_csv(f\"{DATA_PATH}/{data_name}_train.tsv\", sep=\"\\t\")]\n","    valid_df += [pd.read_csv(f\"{DATA_PATH}/{data_name}_valid.tsv\", sep=\"\\t\")]\n","    test_df += [pd.read_csv(f\"{DATA_PATH}/{data_name}_test.tsv\", sep=\"\\t\")]\n","\n","train_df.append(test_df.pop(1))\n","train_df = pd.concat(train_df)\n","valid_df = pd.concat(valid_df)\n","test_df = pd.concat(test_df)\n","\n","train_df.to_csv(\"mix_train.tsv\", sep=\"\\t\", index=False)\n","valid_df.to_csv(\"mix_valid.tsv\", sep=\"\\t\", index=False)\n","test_df.to_csv(\"mix_test.tsv\", sep=\"\\t\", index=False)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EvjX2S_WkRF8"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"k8Twwhw9zPdJ","executionInfo":{"status":"ok","timestamp":1606111361003,"user_tz":480,"elapsed":2010,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["TEXT = Field(\n","    sequential=True,\n","    use_vocab=True,\n","    tokenize=word_tokenize,\n","    lower=True,\n","    batch_first=True,\n",")\n","LABEL = Field(\n","    sequential=False,\n","    use_vocab=False,\n","    batch_first=True,\n",")\n","\n","\n","mix_train_data, mix_valid_data, mix_test_data = TabularDataset.splits(\n","    path=DATA_PATH,\n","    train=\"mix_train.tsv\",\n","    validation=\"mix_valid.tsv\",\n","    test=\"mix_test.tsv\",\n","    format=\"tsv\",\n","    fields=[(\"text\", TEXT), (\"label\", LABEL)],\n","    skip_header=1,\n",")\n","\n","TEXT.build_vocab(mix_train_data, min_freq=2)\n","\n","\n","mix_train_iterator, mix_valid_iterator, mix_test_iterator = BucketIterator.splits(\n","    (mix_train_data, mix_valid_data, mix_test_data),\n","    batch_size=32,\n","    device=None,\n","    sort=False,\n",")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NaBRroeFkRF8"},"source":["## LSTM Classifier"]},{"cell_type":"code","metadata":{"id":"-ycMzmLHzbI9","executionInfo":{"status":"ok","timestamp":1606111362295,"user_tz":480,"elapsed":381,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["class LSTMClassifier(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, hidden_size, num_layers, pad_idx):\n","        super().__init__()\n","        self.embed_layer = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim, padding_idx=pad_idx)\n","        self.lstm_layer = nn.LSTM(\n","            input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, bidirectional=True, dropout=0.5\n","        )\n","        self.last_layer = nn.Sequential(\n","            nn.Linear(hidden_size * 2, hidden_size),\n","            nn.Dropout(0.5),\n","            nn.LeakyReLU(),\n","            nn.Linear(hidden_size, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        embed_x = self.embed_layer(x)\n","        output, (_, _) = self.lstm_layer(embed_x)\n","        last_output = output[:, -1, :]\n","        last_output = self.last_layer(last_output)\n","        return last_output"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHX9pXijzdKM","executionInfo":{"status":"ok","timestamp":1606111364076,"user_tz":480,"elapsed":527,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["def train(model: nn.Module, iterator: Iterator, optimizer: torch.optim.Optimizer, criterion: nn.Module, device: str):\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for _, batch in enumerate(iterator):\n","        optimizer.zero_grad()\n","\n","        text = batch.text\n","        if text.shape[0] > 1:\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def evaluate(model: nn.Module, iterator: Iterator, criterion: nn.Module, device: str):\n","    model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","        for _, batch in enumerate(iterator):\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","            label = label.to(device)\n","            output = model(text).flatten()\n","            loss = criterion(output, label)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)\n","\n","\n","def test(model: nn.Module, iterator: Iterator, device: str):\n","\n","    with torch.no_grad():\n","        y_real = []\n","        y_pred = []\n","        model.eval()\n","        for batch in iterator:\n","            text = batch.text\n","            label = batch.label.type(torch.FloatTensor)\n","            text = text.to(device)\n","\n","            output = model(text).flatten().cpu()\n","\n","            y_real += [label]\n","            y_pred += [output]\n","\n","        y_real = torch.cat(y_real)\n","        y_pred = torch.cat(y_pred)\n","\n","    fpr, tpr, _ = roc_curve(y_real, y_pred)\n","    auroc = auc(fpr, tpr)\n","\n","    return auroc\n","\n","\n","def epoch_time(start_time: int, end_time: int):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqYq9AypkRF9"},"source":["## Pretrain with cola dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so3L6wyQzeEI","executionInfo":{"status":"ok","timestamp":1606111513043,"user_tz":480,"elapsed":146108,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"073d83a6-cae1-4142-8a29-5d694d541393"},"source":["PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","N_EPOCHS = 20\n","\n","lstm_classifier = LSTMClassifier(\n","    num_embeddings=len(TEXT.vocab),\n","    embedding_dim=100,\n","    hidden_size=200,\n","    num_layers=4,\n","    pad_idx=PAD_IDX,\n",")\n","if torch.cuda.is_available():\n","    device = \"cuda:0\"\n","else:\n","    device = \"cpu\"\n","_ = lstm_classifier.to(device)\n","\n","optimizer = torch.optim.Adam(lstm_classifier.parameters())\n","bce_loss_fn = nn.BCELoss()\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(lstm_classifier, mix_train_iterator, optimizer, bce_loss_fn, device)\n","    valid_loss = evaluate(lstm_classifier, mix_valid_iterator, bce_loss_fn, device)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"\\tTrain Loss: {train_loss:.5f}\")\n","    print(f\"\\t Val. Loss: {valid_loss:.5f}\")\n","\n","test_auroc = test(lstm_classifier, mix_test_iterator, device)\n","\n","print(f\"| SAT Dataset Test AUROC: {test_auroc:.5f}\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch: 01 | Time: 0m 6s\n","\tTrain Loss: 0.61426\n","\t Val. Loss: 0.61013\n","Epoch: 02 | Time: 0m 6s\n","\tTrain Loss: 0.61105\n","\t Val. Loss: 0.61659\n","Epoch: 03 | Time: 0m 6s\n","\tTrain Loss: 0.60937\n","\t Val. Loss: 0.60751\n","Epoch: 04 | Time: 0m 6s\n","\tTrain Loss: 0.61026\n","\t Val. Loss: 0.61041\n","Epoch: 05 | Time: 0m 6s\n","\tTrain Loss: 0.63725\n","\t Val. Loss: 0.61229\n","Epoch: 06 | Time: 0m 6s\n","\tTrain Loss: 0.60929\n","\t Val. Loss: 0.60745\n","Epoch: 07 | Time: 0m 6s\n","\tTrain Loss: 0.60911\n","\t Val. Loss: 0.60779\n","Epoch: 08 | Time: 0m 6s\n","\tTrain Loss: 0.60752\n","\t Val. Loss: 0.60850\n","Epoch: 09 | Time: 0m 6s\n","\tTrain Loss: 0.60842\n","\t Val. Loss: 0.60936\n","Epoch: 10 | Time: 0m 6s\n","\tTrain Loss: 0.60775\n","\t Val. Loss: 0.60795\n","Epoch: 11 | Time: 0m 6s\n","\tTrain Loss: 0.60837\n","\t Val. Loss: 0.60838\n","Epoch: 12 | Time: 0m 6s\n","\tTrain Loss: 0.60814\n","\t Val. Loss: 0.60780\n","Epoch: 13 | Time: 0m 6s\n","\tTrain Loss: 0.60756\n","\t Val. Loss: 0.60844\n","Epoch: 14 | Time: 0m 6s\n","\tTrain Loss: 0.60784\n","\t Val. Loss: 0.60756\n","Epoch: 15 | Time: 0m 6s\n","\tTrain Loss: 0.60693\n","\t Val. Loss: 0.60760\n","Epoch: 16 | Time: 0m 6s\n","\tTrain Loss: 0.60768\n","\t Val. Loss: 0.60861\n","Epoch: 17 | Time: 0m 6s\n","\tTrain Loss: 0.60771\n","\t Val. Loss: 0.60771\n","Epoch: 18 | Time: 0m 6s\n","\tTrain Loss: 0.60687\n","\t Val. Loss: 0.60767\n","Epoch: 19 | Time: 0m 6s\n","\tTrain Loss: 0.60696\n","\t Val. Loss: 0.60782\n","Epoch: 20 | Time: 0m 6s\n","\tTrain Loss: 0.60741\n","\t Val. Loss: 0.60774\n","| SAT Dataset Test AUROC: 0.41919\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_-a20XpdJZx","executionInfo":{"status":"ok","timestamp":1606111513044,"user_tz":480,"elapsed":135537,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"1e2195e1-f68e-4f2d-d459-4c82e1e304b4"},"source":["lstm_sat_test_auroc = test(lstm_classifier, mix_test_iterator, device)\n","print(f'| SAT Dataset Test AUROC: {lstm_sat_test_auroc:.5f}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["| SAT Dataset Test AUROC: 0.41919\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v_LrY612srgT","executionInfo":{"status":"ok","timestamp":1606111513044,"user_tz":480,"elapsed":130669,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}}},"source":["def demo(classifier, device):\n","    sat_test = [ \n","        \"Speculations about the meaning and purpose of prehistoric art [rely] heavily on analogies drawn with modern-day hunter-gatherer societies.\",\n","        \"Such primitive societies, [as] Steven Mithen emphasizes in The Prehistory of the Modern Mind, tend to view man and beast, animal and plant, organic and inorganic spheres, as participants in an integrated, animated totality.\",\n","        \"The dual expressions of this tendency are anthropomorphism (the practice of regarding animals as humans) and totemism (the practice of regarding humans as animals), both of [which] spread through the visual art and the mythology of primitive cultures.\",\n","        \"When considered in this light, the visual preoccupation of early humans with the nonhuman creatures [inhabited] their world becomes profoundly meaningful.\",\n","        \"In the practice of totemism, he has suggested, an unlettered humanity “broods upon [itself] and its place in nature.”\",\n","    ]\n","    sat_label = [1, 1, 1, 0, 1]\n","    sat_test = list(map(lambda x: x.replace(\"[\", \"\").replace(\"]\", \"\"), sat_test))\n","    tokenized_sentences = [word_tokenize(sentence) for sentence in sat_test]\n","    sentences = []\n","    for tokenized_sentence in tokenized_sentences:\n","        sentences.append([TEXT.vocab.stoi[word] for word in tokenized_sentence])\n","\n","    predict = []\n","    for sentence in sentences:\n","        sentence = torch.LongTensor([sentence])\n","        predict += [lstm_classifier(sentence.to(device)).item()]\n","    return predict"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-yiiBMXsss4","executionInfo":{"status":"ok","timestamp":1606111519728,"user_tz":480,"elapsed":394,"user":{"displayName":"J JS","photoUrl":"","userId":"03523663544813654809"}},"outputId":"aef17236-f6be-450b-cf4c-8cf2efe7ed70"},"source":["demo(lstm_classifier, device)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7096898555755615,\n"," 0.7096898555755615,\n"," 0.7096898555755615,\n"," 0.7096898555755615,\n"," 0.7095038890838623]"]},"metadata":{"tags":[]},"execution_count":11}]}]}